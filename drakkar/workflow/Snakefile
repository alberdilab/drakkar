import os
import gzip
import json
import pandas as pd
from glob import glob

####
# Define config variables
####

configfile: "workflow/config.yaml"
WORKFLOW = config.get("workflow", None)
OUTPUT_DIR = config.get("output_dir", None)
REFERENCE = config.get("reference", None)
CATALOGING_MODE = config["cataloging_mode"].split(",") if "cataloging_mode" in config else []

####
# Calculate optimal resources for computing
####

def calculate_file_sizes(file_dict):
    """Calculates file sizes in megabases (MB) for each sample's read files."""
    file_sizes = {}
    for sample, files in file_dict.items():
        total_size_mb = 0  # Size in MB

        for file_path in files:
            if os.path.exists(file_path):  # Check if file exists
                file_size = os.path.getsize(file_path) / 1e6  # Convert bytes to MB
                total_size_mb += file_size
            else:
                print(f"⚠️ Warning: File not found - {file_path}")

        file_sizes[sample] = total_size_mb  # Store total size per sample
    return file_sizes

####
# Run pipelines
####

# Run preparing
include: "rules/preparing.smk"

if WORKFLOW == "complete":
    rule all:
        input:
            "results/complete.txt"

    include: "rules/preprocessing.smk"
    include: "rules/cataloging.smk"
    include: "rules/annotation.smk"
    include: "rules/quantification.smk"

if WORKFLOW == "preprocessing":

    with open(f"{OUTPUT_DIR}/data/sample_to_reads1.json", "r") as f:
        SAMPLE_TO_READS1 = json.load(f)

    with open(f"{OUTPUT_DIR}/data/sample_to_reads2.json", "r") as f:
        SAMPLE_TO_READS2 = json.load(f)

    with open(f"{OUTPUT_DIR}/data/reference_to_file.json", "r") as f:
        REFERENCE_TO_FILE = json.load(f)

    with open(f"{OUTPUT_DIR}/data/sample_to_reference.json", "r") as f:
        SAMPLE_TO_REFERENCE = json.load(f)

    samples = list(SAMPLE_TO_READS1.keys())
    references = list(REFERENCE_TO_FILE.keys())

    reads_mb = calculate_file_sizes(SAMPLE_TO_READS1)
    reads_mb_total = sum(reads_mb.values())

    reference_mb = calculate_file_sizes(REFERENCE_TO_FILE)
    reference_mb_total = sum(reference_mb.values())ç

    # The rules reference_index, reference_map, metagenomic_reads and host_reads are only run if
    # the reference genome file is provided. Otherwise, the fastp rule already outputs the final files.

    if REFERENCE:

        rule all:
            input:
                expand(f"{OUTPUT_DIR}/data/references/{{reference}}.fna", reference=references),
                expand(f"{OUTPUT_DIR}/data/references/{{reference}}.rev.1.bt2", reference=references),
                expand(f"{OUTPUT_DIR}/preprocessing/final/{{sample}}_1.fq.gz", sample=samples),
                expand(f"{OUTPUT_DIR}/preprocessing/final/{{sample}}_2.fq.gz", sample=samples),
                expand(f"{OUTPUT_DIR}/preprocessing/final/{{sample}}.bam", sample=samples)

        include: "rules/preprocessing_ref.smk"

    else:

        rule all:
            input:
                expand(f"{OUTPUT_DIR}/preprocessing/final/{{sample}}_1.fq.gz", sample=samples),
                expand(f"{OUTPUT_DIR}/preprocessing/final/{{sample}}_2.fq.gz", sample=samples)

        include: "rules/preprocessing.smk"

if WORKFLOW == "cataloging":

    samples, = glob_wildcards(f"{PREPROCESS_DIR}/{{sample}}_1.fq.gz")

    preprocess_mb = calculate_file_sizes(PREPROCESS_DIR)
    preprocess_mb = {key.replace('_1.fq.gz', ''): value for key, value in preprocess_mb.items()}
    preprocess_mb_total = sum(preprocess_mb.values())

    # A single cataloging rule is created, as multiple cataloging modes can be combined
    rule all:
        input:
            *([expand(f"{OUTPUT_DIR}/cataloging/metabat2/{{sample}}/{{sample}}.tsv", sample=samples)] if "individual" in CATALOGING_MODE else []),
            *([expand(f"{OUTPUT_DIR}/cataloging/maxbin2/{{sample}}/{{sample}}.tsv", sample=samples)] if "individual" in CATALOGING_MODE else []),
            *([f"{OUTPUT_DIR}/cataloging/metabat2/all/all.tsv"] if "all" in CATALOGING_MODE else []),
            *([f"{OUTPUT_DIR}/cataloging/maxbin2/all/all.tsv"] if "all" in CATALOGING_MODE else [])

    if "individual" in CATALOGING_MODE:
        include: "rules/cataloging_ind.smk"

    if "all" in CATALOGING_MODE:
        include: "rules/cataloging_all.smk"
